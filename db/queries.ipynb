{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries on data from jupyter reproducibility study\n",
    "\n",
    "joined-data.feather created by db-to-df.ipynb\n",
    "\n",
    "We produce various queries to sample subsets of repos to compare execution results with repo2docker to results in [this prior study](https://zenodo.org/record/2592524)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the stored data, cached from an export of the above dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.98 s, sys: 693 ms, total: 2.67 s\n",
      "Wall time: 2.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>commit</th>\n",
       "      <th>notebook</th>\n",
       "      <th>reason</th>\n",
       "      <th>exmode</th>\n",
       "      <th>exskip</th>\n",
       "      <th>nbskip</th>\n",
       "      <th>language</th>\n",
       "      <th>language_version</th>\n",
       "      <th>processed_execution</th>\n",
       "      <th>processed_notebook</th>\n",
       "      <th>processed_repo</th>\n",
       "      <th>setups_count</th>\n",
       "      <th>setups</th>\n",
       "      <th>requirements_count</th>\n",
       "      <th>requirements</th>\n",
       "      <th>pipfiles_count</th>\n",
       "      <th>pipfiles</th>\n",
       "      <th>pipfile_locks_count</th>\n",
       "      <th>pipfile_locks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tambetm/pgexperiments</td>\n",
       "      <td>ad4dada7dfe4c5fb8323597f73129157ede4b5fd</td>\n",
       "      <td>MNIST_PG_running_mean.ipynb</td>\n",
       "      <td>ImportError</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>python</td>\n",
       "      <td>2.7.14</td>\n",
       "      <td>39.0</td>\n",
       "      <td>131104</td>\n",
       "      <td>8329</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JonnyRed/IPython-Notebooks</td>\n",
       "      <td>6675f32167646efbda1df575686de9becf3e4f85</td>\n",
       "      <td>YoungAndFreedman13/Chapter04-Newtons-Laws-of-M...</td>\n",
       "      <td>&lt;Install Dependency Error&gt;</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>python</td>\n",
       "      <td>2.7.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8224</td>\n",
       "      <td>8329</td>\n",
       "      <td>1</td>\n",
       "      <td>SciPy_SymPy/ipython_doctester/setup.py</td>\n",
       "      <td>1</td>\n",
       "      <td>Numerical-Python/requirements.txt</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vshaumann/Test</td>\n",
       "      <td>bee2b00d04e0366046e6b25820b43e6ae0a78405</td>\n",
       "      <td>KS Divergence.ipynb</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>python</td>\n",
       "      <td>3.6.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>131104</td>\n",
       "      <td>8329</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Henrilin28/ADS_Final_Homeless</td>\n",
       "      <td>57378e27768bb4627883eef243d892901a174a11</td>\n",
       "      <td>Time series plots/SingleWomenTimesSeries.ipynb</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>python</td>\n",
       "      <td>2.7.12</td>\n",
       "      <td>35.0</td>\n",
       "      <td>131104</td>\n",
       "      <td>8329</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>luoyuweidu/Script</td>\n",
       "      <td>f0f0bcdfeef66312f73a5c0c9dabeb5fe406a699</td>\n",
       "      <td>ASSO - getting receipts.ipynb</td>\n",
       "      <td>error</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>python</td>\n",
       "      <td>2.7.13</td>\n",
       "      <td>39.0</td>\n",
       "      <td>131104</td>\n",
       "      <td>8329</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450072</th>\n",
       "      <td>cjwinchester/2018-03-09-nicar-class</td>\n",
       "      <td>7d05fe55e5181aa2c44d8989d2851d22196633e9</td>\n",
       "      <td>completed/18. Setting up Python on your own co...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>416</td>\n",
       "      <td>python</td>\n",
       "      <td>3.6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>8329</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>requirements.txt</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450073</th>\n",
       "      <td>tjh1997/pandas_exercises</td>\n",
       "      <td>3da2d91d8b4080520d0bccd053fe17bd23c702eb</td>\n",
       "      <td>09_Time_Series/Getting_Financial_Data/Exercise...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>416</td>\n",
       "      <td>python</td>\n",
       "      <td>2.7.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>8329</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450074</th>\n",
       "      <td>pzz2011/demos.ml</td>\n",
       "      <td>3e3f622408859f1f2f791c642f066d00d0e41d4b</td>\n",
       "      <td>jupyter/notebooks/Spark/SparkR/ApacheArrow-Fea...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "      <td>R</td>\n",
       "      <td>3.3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>8329</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450075</th>\n",
       "      <td>cfchang/cs591</td>\n",
       "      <td>18d5c7f3db291f8814ec5a2b1f5e9b66528cb44a</td>\n",
       "      <td>Homework-4/4.Food-recipes.ipynb</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>8329</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450076</th>\n",
       "      <td>icodingc/practice-torch</td>\n",
       "      <td>486754cc5ea251f1d2b6324d6aac3f693d36ff59</td>\n",
       "      <td>practical44/practical_requ.ipynb</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>lua</td>\n",
       "      <td>20100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>8329</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1450077 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        repo  \\\n",
       "0                      tambetm/pgexperiments   \n",
       "1                 JonnyRed/IPython-Notebooks   \n",
       "2                             vshaumann/Test   \n",
       "3              Henrilin28/ADS_Final_Homeless   \n",
       "4                          luoyuweidu/Script   \n",
       "...                                      ...   \n",
       "1450072  cjwinchester/2018-03-09-nicar-class   \n",
       "1450073             tjh1997/pandas_exercises   \n",
       "1450074                     pzz2011/demos.ml   \n",
       "1450075                        cfchang/cs591   \n",
       "1450076              icodingc/practice-torch   \n",
       "\n",
       "                                           commit  \\\n",
       "0        ad4dada7dfe4c5fb8323597f73129157ede4b5fd   \n",
       "1        6675f32167646efbda1df575686de9becf3e4f85   \n",
       "2        bee2b00d04e0366046e6b25820b43e6ae0a78405   \n",
       "3        57378e27768bb4627883eef243d892901a174a11   \n",
       "4        f0f0bcdfeef66312f73a5c0c9dabeb5fe406a699   \n",
       "...                                           ...   \n",
       "1450072  7d05fe55e5181aa2c44d8989d2851d22196633e9   \n",
       "1450073  3da2d91d8b4080520d0bccd053fe17bd23c702eb   \n",
       "1450074  3e3f622408859f1f2f791c642f066d00d0e41d4b   \n",
       "1450075  18d5c7f3db291f8814ec5a2b1f5e9b66528cb44a   \n",
       "1450076  486754cc5ea251f1d2b6324d6aac3f693d36ff59   \n",
       "\n",
       "                                                  notebook  \\\n",
       "0                              MNIST_PG_running_mean.ipynb   \n",
       "1        YoungAndFreedman13/Chapter04-Newtons-Laws-of-M...   \n",
       "2                                      KS Divergence.ipynb   \n",
       "3           Time series plots/SingleWomenTimesSeries.ipynb   \n",
       "4                            ASSO - getting receipts.ipynb   \n",
       "...                                                    ...   \n",
       "1450072  completed/18. Setting up Python on your own co...   \n",
       "1450073  09_Time_Series/Getting_Financial_Data/Exercise...   \n",
       "1450074  jupyter/notebooks/Spark/SparkR/ApacheArrow-Fea...   \n",
       "1450075                    Homework-4/4.Food-recipes.ipynb   \n",
       "1450076                   practical44/practical_requ.ipynb   \n",
       "\n",
       "                             reason  exmode  exskip  nbskip language  \\\n",
       "0                       ImportError     5.0     0.0       0   python   \n",
       "1        <Install Dependency Error>     3.0     0.0       0   python   \n",
       "2                              None     5.0     0.0       0   python   \n",
       "3                              None     5.0     0.0       0   python   \n",
       "4                             error     5.0     0.0       0   python   \n",
       "...                             ...     ...     ...     ...      ...   \n",
       "1450072                        None     NaN     NaN     416   python   \n",
       "1450073                        None     NaN     NaN     416   python   \n",
       "1450074                        None     NaN     NaN     128        R   \n",
       "1450075                        None     NaN     NaN      96  unknown   \n",
       "1450076                        None     NaN     NaN       0      lua   \n",
       "\n",
       "        language_version  processed_execution  processed_notebook  \\\n",
       "0                 2.7.14                 39.0              131104   \n",
       "1                  2.7.8                  0.0                8224   \n",
       "2                  3.6.0                 35.0              131104   \n",
       "3                 2.7.12                 35.0              131104   \n",
       "4                 2.7.13                 39.0              131104   \n",
       "...                  ...                  ...                 ...   \n",
       "1450072            3.6.4                  NaN                  32   \n",
       "1450073           2.7.11                  NaN                  32   \n",
       "1450074            3.3.0                  NaN                  32   \n",
       "1450075          unknown                  NaN                  32   \n",
       "1450076            20100                  NaN                  32   \n",
       "\n",
       "         processed_repo  setups_count                                  setups  \\\n",
       "0                  8329             0                                           \n",
       "1                  8329             1  SciPy_SymPy/ipython_doctester/setup.py   \n",
       "2                  8329             0                                           \n",
       "3                  8329             0                                           \n",
       "4                  8329             0                                           \n",
       "...                 ...           ...                                     ...   \n",
       "1450072            8329             0                                           \n",
       "1450073            8329             0                                           \n",
       "1450074            8329             0                                           \n",
       "1450075            8329             0                                           \n",
       "1450076            8329             0                                           \n",
       "\n",
       "         requirements_count                       requirements  \\\n",
       "0                         0                                      \n",
       "1                         1  Numerical-Python/requirements.txt   \n",
       "2                         0                                      \n",
       "3                         0                                      \n",
       "4                         0                                      \n",
       "...                     ...                                ...   \n",
       "1450072                   1                   requirements.txt   \n",
       "1450073                   0                                      \n",
       "1450074                   0                                      \n",
       "1450075                   0                                      \n",
       "1450076                   0                                      \n",
       "\n",
       "         pipfiles_count pipfiles  pipfile_locks_count pipfile_locks  \n",
       "0                     0                             0                \n",
       "1                     0                             0                \n",
       "2                     0                             0                \n",
       "3                     0                             0                \n",
       "4                     0                             0                \n",
       "...                 ...      ...                  ...           ...  \n",
       "1450072               0                             0                \n",
       "1450073               0                             0                \n",
       "1450074               0                             0                \n",
       "1450075               0                             0                \n",
       "1450076               0                             0                \n",
       "\n",
       "[1450077 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_feather(\"joined-data.feather\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "python      1334002\n",
       "unknown       78021\n",
       "r             16860\n",
       "julia         12028\n",
       "scala          1518\n",
       "bash           1008\n",
       "lua             698\n",
       "ruby            655\n",
       "octave          625\n",
       "scala211        593\n",
       "Name: notebook, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"language\"] = df[\"language\"].str.lower()\n",
    "df.groupby(\"language\").notebook.count().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create task lists of repositories to test,\n",
    "based on certain queries. To do this, we have a `save_grouped` function\n",
    "that dumps a list of repos and commits, with info about the number of notebooks,\n",
    "their language(s), and language versions.\n",
    "\n",
    "So far, we have the following interesting queries:\n",
    "\n",
    "1. Julia notebooks\n",
    "2. R notebooks\n",
    "3. repos where installation failed\n",
    "4. repos where execution succeeded after dependency installation (Python-only because the prior study only executed Python)\n",
    "5. repos where execution succeeded with anaconda, without dependencies specified (Python-only)\n",
    "6. repos where execution succeeded *and* environment is specified with top-level `requirements.txt` (subset of 4 where we know repo2docker will find the requirements.txt)\n",
    "7. repos where failure is due to import error or ModuleNotFound, indicating a missing dependency\n",
    "\n",
    "The database stored these status labels in a bitmask `executions.processed` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_labels = {\n",
    "    0b000000: \"failed to install\",\n",
    "    0b000001: \"installed\",\n",
    "    0b000010: \"loaded\",\n",
    "    0b000100: \"exception\",\n",
    "    0b001000: \"timeout\",\n",
    "    0b010000: \"same results\",\n",
    "    0b100000: \"ok\",\n",
    "}\n",
    "status = {label:mask for mask, label in status_labels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1 # set random seed for reproducible output\n",
    "\n",
    "\n",
    "def agg_unique(x):\n",
    "    \"\"\"Aggregator to return comma-separated unique values\"\"\"\n",
    "    return \";\".join(sorted(x.unique()))\n",
    "\n",
    "\n",
    "def save_grouped(df, dest, limit=None, sort=True):\n",
    "    \"\"\"Save a subset of data to a .txt file,\n",
    "    \n",
    "    grouped by repo, showing set of languages and number of notebooks\n",
    "    \"\"\"\n",
    "    grouped = df.groupby([\"repo\", \"commit\"]).agg(\n",
    "        {\n",
    "        \"notebook\": \"count\",\n",
    "        \"language\": agg_unique,\n",
    "        \"language_version\": agg_unique,\n",
    "        }\n",
    "    ).reset_index()\n",
    "    if sort:\n",
    "        grouped = grouped.sort_values(\"notebook\")\n",
    "    else:\n",
    "        # random order\n",
    "        grouped = grouped.sample(frac=1, random_state=random_seed)\n",
    "    with open(dest, \"w\") as f:\n",
    "        f.write(f\"{'repo'.rjust(40)}, {'commit'.rjust(40)}, notebooks, language, version\\n\")\n",
    "        limited = grouped[:limit]\n",
    "        for idx, row in limited.iterrows():\n",
    "            f.write(f\"{row.repo.rjust(40)}, {row.commit}, {row.notebook:9}, {row.language.rjust(9)}, {row.language_version.rjust(7)}\\n\")\n",
    "    print(f\"Wrote {len(limited)}/{len(grouped)} records to {dest}\")\n",
    "            \n",
    "\n",
    "def matching_repos(mask, mode='any'):\n",
    "    \"\"\"Expand a subset applied at the notebook or execution level to all records\n",
    "    for matching repos.\n",
    "    \n",
    "    Match mode can be 'any' (any records for a given repo match)\n",
    "    or 'all' (all records for a given repo match)\n",
    "    \n",
    "    Because groupby.filter(mask.any()) takes 100 times as long\n",
    "    \"\"\"\n",
    "    if mode == 'all':\n",
    "        # De Morgan: all = not (not any)\n",
    "        not_any = df[~mask]\n",
    "        unmatching_repos = not_any.repo.unique()\n",
    "        return df[~df.repo.isin(unmatching_repos)]\n",
    "    elif mode == 'any':\n",
    "        subset = df[mask]\n",
    "        matching_repos = subset.repo.unique()\n",
    "        return df[df.repo.isin(matching_repos)]\n",
    "    else:\n",
    "        raise ValueError(f\"mode must be 'any' or 'all', not '{mode}''\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Julia notebooks\n",
    "\n",
    "Collect all of the repositories with at least one julia notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2328 repos containing some Julia notebooks\n"
     ]
    }
   ],
   "source": [
    "julia = matching_repos(df[\"language\"] == \"julia\")\n",
    "print(f\"{len(julia.repo.unique())} repos containing some Julia notebooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1630 repos containing only Julia notebooks\n"
     ]
    }
   ],
   "source": [
    "all_julia = matching_repos(df[\"language\"] == \"julia\", mode='all')\n",
    "print(f\"{len(all_julia.repo.unique())} repos containing only Julia notebooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 1000/1630 records to julia.txt\n"
     ]
    }
   ],
   "source": [
    "save_grouped(all_julia, \"julia.txt\", limit=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R notebooks\n",
    "\n",
    "same as Julia, but for R!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2501 repos containing only R notebooks\n",
      "Wrote 1000/2501 records to r.txt\n"
     ]
    }
   ],
   "source": [
    "r = julia = matching_repos(df[\"language\"] == \"r\", \"all\")\n",
    "print(f\"{len(r.repo.unique())} repos containing only R notebooks\")\n",
    "save_grouped(r, \"r.txt\", limit=1000, sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  failed installation\n",
    "\n",
    "A failed installation occurs when the \"execution mode\" == 3 (install with dependencies) and \"processed_execution\" is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 1000/11877 records to install-failed.txt\n"
     ]
    }
   ],
   "source": [
    "install_failed_mask = (df[\"processed_execution\"] == status[\"failed to install\"]) & (df[\"exmode\"] == 3)\n",
    "install_failed = matching_repos(install_failed_mask)\n",
    "save_grouped(install_failed, \"install-failed.txt\", sort=False, limit=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# success\n",
    "\n",
    "We explore various versions of success\n",
    "\n",
    "- exmode == 3 (found and installed dependencies)\n",
    "- exmode == 5 (found no dependencies, ran with anaconda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.,  3., nan,  4.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"exmode\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract successful runs from the `processed_execution` bitmask:\n",
    "\n",
    "- OK, AND NOT\n",
    "- Exception, AND NOT\n",
    "- Timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_mask = ~df[\"processed_execution\"].isna()\n",
    "without_unprocessed = df.loc[processed_mask]\n",
    "# success mask: ok AND NOT exception or timeout\n",
    "success_mask = (\n",
    "    without_unprocessed[\"processed_execution\"].astype(int) & (\n",
    "        status[\"ok\"] | status[\"exception\"] | status[\"timeout\"]\n",
    "    ) == status[\"ok\"]\n",
    ")\n",
    "# define new boolean success column with the result\n",
    "df.loc[processed_mask, \"success\"] = success_mask\n",
    "# recreate the view with new column\n",
    "without_unprocessed = df.loc[processed_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution success rate with installed dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success rate after successful installation of dependencies: 7.6%\n"
     ]
    }
   ],
   "source": [
    "rate = df[df.exmode == 3].success.mean()\n",
    "print(f\"success rate after successful installation of dependencies: {round(rate * 100, 1)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the success rate for notebooks without specified dependencies, but run in Anaconda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success rate without specified dependencies, run in Anaconda: 24.9%\n"
     ]
    }
   ],
   "source": [
    "rate = df[df.exmode == 5].success.mean()\n",
    "print(f\"success rate without specified dependencies, run in Anaconda: {round(rate * 100, 1)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the fraction of runs for \"success with dependencies\" where\n",
    "a top-level `requirements.txt` is used.\n",
    "These are repos we should expect repo2docker to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9623 notebooks successfully executed with some requirements.txt specified\n"
     ]
    }
   ],
   "source": [
    "req_success = df[\n",
    "    (df.exmode == 3)\n",
    "    & df.success\n",
    "    & df.requirements_count\n",
    "]\n",
    "print(f\"{len(req_success)} notebooks successfully executed with some requirements.txt specified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the fraction of these where a top-level requirements.txt is used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of successful executions with only standard top-level requirements.txt: 54%\n"
     ]
    }
   ],
   "source": [
    "rate = (req_success[\"requirements\"] == \"requirements.txt\").mean()\n",
    "print(f\"Fraction of successful executions with only standard top-level requirements.txt: {rate * 100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the number of requirements.txt files for successful runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requirements_count\n",
       "1     2649\n",
       "3       58\n",
       "5       26\n",
       "7       12\n",
       "9       16\n",
       "11     265\n",
       "13       9\n",
       "15       1\n",
       "17       1\n",
       "33       1\n",
       "Name: repo, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req_success.groupby(\"requirements_count\").repo.agg(lambda x: len(x.unique())).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same data as above, showing groupings of layouts,\n",
    "indicating that many of the multi-requirements layouts are for repos with identical layout,\n",
    "such as those created for online courses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requirements\n",
       "sentiment-network/requirements.txt;weight-initialization/requirements.txt;intro-to-tflearn/requirements.txt;tensorboard/requirements.txt;intro-to-tensorflow/requirements.txt;first-neural-network/requirements.txt;transfer-learning/requirements.txt;sentiment-rnn/requirements.txt;embeddings/requirements.txt;tv-script-generation/requirements.txt;intro-to-rnns/requirements.txt      52\n",
       "requirements/requirements.txt                                                                                                                                                                                                                                                                                                                                                               52\n",
       "aimacode/requirements.txt                                                                                                                                                                                                                                                                                                                                                                   80\n",
       "embeddings/requirements.txt;first-neural-network/requirements.txt;intro-to-rnns/requirements.txt;intro-to-tensorflow/requirements.txt;intro-to-tflearn/requirements.txt;sentiment-network/requirements.txt;sentiment-rnn/requirements.txt;tensorboard/requirements.txt;transfer-learning/requirements.txt;tv-script-generation/requirements.txt;weight-initialization/requirements.txt     136\n",
       "requirements.txt                                                                                                                                                                                                                                                                                                                                                                          1975\n",
       "Name: repo, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req_success.groupby(\"requirements\").repo.agg(lambda x: len(x.unique())).sort_values().tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create lists of repos with complete success:\n",
    "\n",
    "1. success with dependencies\n",
    "2. success with dependencies where there is exactly one top-level requirements.txt\n",
    "3. success without dependencies (with anaconda) — we don't expect much success with repo2docker here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 971/971 records to success-with-dependencies.txt\n",
      "CPU times: user 1.45 s, sys: 159 ms, total: 1.61 s\n",
      "Wall time: 1.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "successful_repos = matching_repos(df[\"success\"] & (df[\"exmode\"] == 3), mode=\"all\")\n",
    "save_grouped(successful_repos, \"success-with-dependencies.txt\", sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 798/798 records to success-default-requirements.txt\n"
     ]
    }
   ],
   "source": [
    "success_default_requirements = successful_repos[successful_repos[\"requirements\"] == \"requirements.txt\"]\n",
    "save_grouped(success_default_requirements, \"success-default-requirements.txt\", sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 1000/25379 records to success-without-dependencies.txt\n"
     ]
    }
   ],
   "source": [
    "success_without_dependencies = matching_repos(\n",
    "    df[\"success\"] & (df[\"exmode\"] == 5),\n",
    "    mode=\"all\",\n",
    ")\n",
    "save_grouped(success_without_dependencies, \"success-without-dependencies.txt\", sort=False, limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 1000/95616 records to import-error.txt\n"
     ]
    }
   ],
   "source": [
    "import_error_mask = df[\"reason\"].str.contains(\"ImportError\") | df[\"reason\"].str.contains(\"ModuleNotFound\")\n",
    "import_errors = matching_repos(import_error_mask)\n",
    "save_grouped(import_errors, \"import-error.txt\", limit=1000, sort=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
