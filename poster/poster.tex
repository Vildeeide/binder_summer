% based on https://www.overleaf.com/latex/templates/writing-posters-with-markdown/jtbgmmgqrqmh

\documentclass{beamer}
%% Possible paper sizes: a0, a0b, a1, a2, a3, a4.
%% Possible orientations: portrait, landscape
%% Font sizes can be changed using the scale option.
\usepackage[size=a3,orientation=landscape,scale=1]{beamerposter}
\usetheme{Simula-poster}
\usecolortheme{simula}

\usepackage{svg}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{helvet}
\usepackage[scaled=0.92]{inconsolata}
% \usepackage[libertine]{newtxmath}
\usepackage{natbib}
\renewcommand{\bibfont}{\small}

\newcommand{\texthash}{\#}


%% Load the markdown package
\usepackage[citations,footnotes,definitionLists,hashEnumerators,smartEllipses,tightLists=false,pipeTables,tableCaptions,hybrid]{markdown}
%%begin novalidate
\markdownSetup{rendererPrototypes={
 link = {\href{#2}{#1}},
 headingFour = {\begin{block}{#1}},
 horizontalRule = {\end{block}}
}}
%%end novalidate

\author[]{Vilde Dille Ã˜vreeide and Min Ragan-Kelley}
\institute[simula]{Simula Research Laboratory}

\title{Measuring notebook reproducibility with repo2docker}
% Optional foot image
\footimage{\includegraphics[width=4cm]{simula-logo.pdf}}

\begin{document}
\begin{frame}[fragile]\centering

\begin{columns}
\begin{column}{0.57\textwidth}

\begin{markdown}

#### Motivation


- A large-scale study of notebook reproducibility was published in 2019 [@reproducibility:2019]
- repo2docker is a tool for automatically generating environments from repos, to aid in reproducibility [@binder2]
- we want to evaluate repo2docker's automatic env generation,
  and compare with the study's conclusions
- Study did not evaluate execution of languages other than Python;
  repo2docker can produce environments with Julia, R, etc.
- repo2docker has no mechanism for evaluating success other than build completing

We built repo2docker-checker [@repo2dockerchecker] to automate
fetching and building repos with repo2docker, then running a test script
to classify whether it should be considered reproducible.


----
\end{markdown}
\end{column}

\begin{column}{.4\textwidth}
\begin{markdown}


#### Caveats

- For repo2docker, our main interest is in *environment reproducibility*,
  not *code reproducibility*,
  so if all dependencies are met, the goal is achieved.
  But how can we tell?

- **What qualifies as a successfully reproducible repo?**
  We chose: repo2docker successfully builds an image, and

    - it has notebooks
    - notebooks execute without error

----

\end{markdown}
\end{column}

\end{columns}

\bigskip
{\usebeamercolor[bg]{headline}\hrulefill}
\bigskip

\begin{columns}[T]

%%%% First Column
\begin{column}{.46\textwidth}

\begin{markdown}

#### Background

- reproduce previous study
- compare with repo2docker
- evaluate "automate existing best practices" claim
- failure to reproduce != repo2docker failure!

----


#### Process

1. collect repositories to test
    - source 1: github search for language:jupyter
    - source 2: queries from [@reproducibility:2019]
2. build image with repo2docker
3. find notebooks in repo (up to 5)
4. execute notebooks with nbconvert


----

#### Categories of notebooks

Based on queries from previous study database, we collected and tested samples of repos,
grouped by classification in the study:

- Julia notebooks (not tested previously)
- R notebooks (not tested previously)
- Installation failed (environment specified, could not install)
- Import error / ModuleNotFound (likely missing dependency specification)
- Success without dependencies (environment not found by study, execution succeeds)
- Success with default dependencies (study ran with anaconda, success)

----

#### Outcomes

Several possible classes of failure,
some of which are interesting for repo2docker,
others are not:

- build failure
    + due to partially pinned environment (e.g. pinned numpy not compatible with Python 3.8)
    + due to pre-build dependencies (e.g. apt-get install C libraries)
    + actually invalid requirements
- execution failure
    + environment not specified at all
    + environment insufficiently specified
    + user input required (e.g. credentials for using an API, or "fill out X before executing")

----


\end{markdown}

\end{column}

%%%% Second Column
\begin{column}{.46\textwidth}

\begin{markdown}



#### Results

% \setkeys{Gin}{width=.3\linewidth}

% ![exampleimage](example-image.jpg "An exemplary image")


| Right | Left | Default | Center |
|------:|:-----|---------|:------:|
|  12   |  12  |  12     |   12   |
| 123   |  123 |   123   |  123   |
|   1   |    1 |     1   |    1   |

  : Demonstration of pipe table syntax.

----

#### Conclusions

- Open data publication in [@reproducibility:2019] greatly facilitates follow-up studies!
- A large fraction of build failures were due to pinning packages (most often numpy or pandas)
  but not Python, because there is no community standard for pinning Python (conda, Pipfile insufficiently common, often lack Python itself)
- repo2docker success rate could be greatly improved if we looked at more of the repo to determine runtime language and/or version:
    + last repository commit date could pick older Python by default (not at all intrusive)
    + notebook \texttt{language info} metadata includes runtime and version (more expensive to evaluate)
- repo2docker does not implement best practices adopted in R and Julia communities
    + big caveat for Julia: most repos tested were older than the advent of the new \texttt{project.toml}

----

#### Future work

- Test repo2docker with different strategies for picking runtimes / versions
- Evaluate more repos, our sample size was small
- Plugin check to Binder for more thorough evaluation of success on build
- Engage with R / Julia community to investigate standards for specifying environments.
  **Is repo2docker missing something, or do these communities not have widely used environment standards?** Specifically, evaluate adoption of recently implemented ``project.toml`` specification.

----

\end{markdown}
\end{column}
\end{columns}

\begin{markdown}


#### Bibliography

\bibliographystyle{unsrtnat}
\bibliography{refs}

----

\end{markdown}

\end{frame}


\end{document}
