[I 200707 13:18:38 inrepo:36] Testing notebook notebooks/03_evaluate/evaluation.ipynb
[W 200707 13:18:38 inrepo:48] No such kernel reco_pyspark, falling back on kernel language=python
[W 200707 13:18:38 inrepo:60] Using kernel python3 to provide language: python
[I 200707 13:18:39 execute:404] Executing notebook with kernel: python3
Traceback (most recent call last):
  File "/src/inrepo.py", line 112, in <module>
    main()
  File "/src/inrepo.py", line 108, in main
    test_f(opts.test, opts.output_dir)
  File "/src/inrepo.py", line 74, in run_notebook
    exported = executenb(nb, cwd=os.path.dirname(nb_path), kernel_name=kernel_name)
  File "/srv/conda/envs/notebook/lib/python3.7/site-packages/nbconvert/preprocessors/execute.py", line 737, in executenb
    return ep.preprocess(nb, resources, km=km)[0]
  File "/srv/conda/envs/notebook/lib/python3.7/site-packages/nbconvert/preprocessors/execute.py", line 405, in preprocess
    nb, resources = super(ExecutePreprocessor, self).preprocess(nb, resources)
  File "/srv/conda/envs/notebook/lib/python3.7/site-packages/nbconvert/preprocessors/base.py", line 69, in preprocess
    nb.cells[index], resources = self.preprocess_cell(cell, resources, index)
  File "/srv/conda/envs/notebook/lib/python3.7/site-packages/nbconvert/preprocessors/execute.py", line 448, in preprocess_cell
    raise CellExecutionError.from_cell_and_msg(cell, out)
nbconvert.preprocessors.execute.CellExecutionError: An error occurred while executing the following cell:
------------------
# set the environment path to find Recommenders
import sys
sys.path.append("../../")
import pandas as pd
import pyspark
from sklearn.preprocessing import minmax_scale

from reco_utils.common.spark_utils import start_or_get_spark
from reco_utils.evaluation.spark_evaluation import SparkRankingEvaluation, SparkRatingEvaluation
from reco_utils.evaluation.python_evaluation import auc, logloss

print("System version: {}".format(sys.version))
print("Pandas version: {}".format(pd.__version__))
print("PySpark version: {}".format(pyspark.__version__))
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mModuleNotFoundError[0m                       Traceback (most recent call last)
[0;32m<ipython-input-1-a99a7645a79e>[0m in [0;36m<module>[0;34m[0m
[1;32m      2[0m [0;32mimport[0m [0msys[0m[0;34m[0m[0;34m[0m[0m
[1;32m      3[0m [0msys[0m[0;34m.[0m[0mpath[0m[0;34m.[0m[0mappend[0m[0;34m([0m[0;34m"../../"[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 4[0;31m [0;32mimport[0m [0mpandas[0m [0;32mas[0m [0mpd[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      5[0m [0;32mimport[0m [0mpyspark[0m[0;34m[0m[0;34m[0m[0m
[1;32m      6[0m [0;32mfrom[0m [0msklearn[0m[0;34m.[0m[0mpreprocessing[0m [0;32mimport[0m [0mminmax_scale[0m[0;34m[0m[0;34m[0m[0m

[0;31mModuleNotFoundError[0m: No module named 'pandas'
ModuleNotFoundError: No module named 'pandas'


Container exited with status: {'Error': None, 'StatusCode': 1}
