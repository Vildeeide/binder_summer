Picked Local content provider.
Using local repo /tmp/r2d-test-2020-07-03T07.200kny96bj/github.com/aamini/introtodeeplearning.
Using PythonBuildPack builder
Step 1/48 : FROM buildpack-deps:bionic
 ---> 5d109dc6d8a0
Step 2/48 : ENV DEBIAN_FRONTEND=noninteractive
 ---> Using cache
 ---> 84875aa039ff
Step 3/48 : RUN apt-get -qq update &&     apt-get -qq install --yes --no-install-recommends locales > /dev/null &&     apt-get -qq purge &&     apt-get -qq clean &&     rm -rf /var/lib/apt/lists/*
 ---> Using cache
 ---> 2c6f3445209c
Step 4/48 : RUN echo "en_US.UTF-8 UTF-8" > /etc/locale.gen &&     locale-gen
 ---> Using cache
 ---> 5ac40a1069ef
Step 5/48 : ENV LC_ALL en_US.UTF-8
 ---> Using cache
 ---> 0569ecd6efb3
Step 6/48 : ENV LANG en_US.UTF-8
 ---> Using cache
 ---> bd3372a8f400
Step 7/48 : ENV LANGUAGE en_US.UTF-8
 ---> Using cache
 ---> ab87a637d837
Step 8/48 : ENV SHELL /bin/bash
 ---> Using cache
 ---> 50ed7363eaf5
Step 9/48 : ARG NB_USER
 ---> Using cache
 ---> 0b8893bd6422
Step 10/48 : ARG NB_UID
 ---> Using cache
 ---> b9e6fa4ea16e
Step 11/48 : ENV USER ${NB_USER}
 ---> Using cache
 ---> b142a4c01942
Step 12/48 : ENV HOME /home/${NB_USER}
 ---> Using cache
 ---> e11d5723ab90
Step 13/48 : RUN groupadd         --gid ${NB_UID}         ${NB_USER} &&     useradd         --comment "Default user"         --create-home         --gid ${NB_UID}         --no-log-init         --shell /bin/bash         --uid ${NB_UID}         ${NB_USER}
 ---> Using cache
 ---> e20a5903ae77
Step 14/48 : RUN wget --quiet -O - https://deb.nodesource.com/gpgkey/nodesource.gpg.key |  apt-key add - &&     DISTRO="bionic" &&     echo "deb https://deb.nodesource.com/node_10.x $DISTRO main" >> /etc/apt/sources.list.d/nodesource.list &&     echo "deb-src https://deb.nodesource.com/node_10.x $DISTRO main" >> /etc/apt/sources.list.d/nodesource.list
 ---> Using cache
 ---> 730bb79c819d
Step 15/48 : RUN apt-get -qq update &&     apt-get -qq install --yes --no-install-recommends        less        nodejs        unzip        > /dev/null &&     apt-get -qq purge &&     apt-get -qq clean &&     rm -rf /var/lib/apt/lists/*
 ---> Using cache
 ---> 2be5b9d2edc7
Step 16/48 : EXPOSE 8888
 ---> Using cache
 ---> 7fcdbaf0fe40
Step 17/48 : ENV APP_BASE /srv
 ---> Using cache
 ---> ee51ea8ec11a
Step 18/48 : ENV NPM_DIR ${APP_BASE}/npm
 ---> Using cache
 ---> f34fdbe18446
Step 19/48 : ENV NPM_CONFIG_GLOBALCONFIG ${NPM_DIR}/npmrc
 ---> Using cache
 ---> 833e25d9d235
Step 20/48 : ENV CONDA_DIR ${APP_BASE}/conda
 ---> Using cache
 ---> 8ee468f15616
Step 21/48 : ENV NB_PYTHON_PREFIX ${CONDA_DIR}/envs/notebook
 ---> Using cache
 ---> 971c9391c0ab
Step 22/48 : ENV KERNEL_PYTHON_PREFIX ${NB_PYTHON_PREFIX}
 ---> Using cache
 ---> 7fa50abe8e21
Step 23/48 : ENV PATH ${NB_PYTHON_PREFIX}/bin:${CONDA_DIR}/bin:${NPM_DIR}/bin:${PATH}
 ---> Using cache
 ---> eaa621b5d97f
Step 24/48 : COPY build_script_files/-2fusr-2flocal-2flib-2fpython3-2e8-2fdist-2dpackages-2frepo2docker-2fbuildpacks-2fconda-2factivate-2dconda-2esh-1be18e /etc/profile.d/activate-conda.sh
 ---> Using cache
 ---> 9ffab983afa0
Step 25/48 : COPY build_script_files/-2fusr-2flocal-2flib-2fpython3-2e8-2fdist-2dpackages-2frepo2docker-2fbuildpacks-2fconda-2fenvironment-2epy-2d3-2e7-2efrozen-2eyml-26bd38 /tmp/environment.yml
 ---> Using cache
 ---> 9b3e6c528ba6
Step 26/48 : COPY build_script_files/-2fusr-2flocal-2flib-2fpython3-2e8-2fdist-2dpackages-2frepo2docker-2fbuildpacks-2fconda-2finstall-2dminiconda-2ebash-813f10 /tmp/install-miniconda.bash
 ---> Using cache
 ---> e52d3b4016a9
Step 27/48 : RUN mkdir -p ${NPM_DIR} && chown -R ${NB_USER}:${NB_USER} ${NPM_DIR}
 ---> Using cache
 ---> 0a8f7bcc0bd7
Step 28/48 : USER ${NB_USER}
 ---> Using cache
 ---> e295fca18e9d
Step 29/48 : RUN npm config --global set prefix ${NPM_DIR}
 ---> Using cache
 ---> b3629329dd8f
Step 30/48 : USER root
 ---> Using cache
 ---> 5ba3698f0957
Step 31/48 : RUN bash /tmp/install-miniconda.bash && rm /tmp/install-miniconda.bash /tmp/environment.yml
 ---> Using cache
 ---> ecb18ec9bb2f
Step 32/48 : ARG REPO_DIR=${HOME}
 ---> Using cache
 ---> 8f78500beba3
Step 33/48 : ENV REPO_DIR ${REPO_DIR}
 ---> Using cache
 ---> 300bfe3eb940
Step 34/48 : WORKDIR ${REPO_DIR}
 ---> Using cache
 ---> ab56d4c94aaf
Step 35/48 : ENV PATH ${HOME}/.local/bin:${REPO_DIR}/.local/bin:${PATH}
 ---> Using cache
 ---> 26a826700420
Step 36/48 : ENV CONDA_DEFAULT_ENV ${KERNEL_PYTHON_PREFIX}
 ---> Using cache
 ---> ebb7f28a23e9
Step 37/48 : USER root
 ---> Using cache
 ---> 4477f562c4c4
Step 38/48 : COPY src/ ${REPO_DIR}
 ---> efe0484809c7
Step 39/48 : RUN chown -R ${NB_USER}:${NB_USER} ${REPO_DIR}
 ---> Running in f8ba63310cfa
Removing intermediate container f8ba63310cfa
 ---> de6917f1e7ef
Step 40/48 : USER ${NB_USER}
 ---> Running in fa40f6e420e1
Removing intermediate container fa40f6e420e1
 ---> c437c7be48d2
Step 41/48 : RUN ${KERNEL_PYTHON_PREFIX}/bin/pip install --no-cache-dir .
 ---> Running in 3aad38e3479f
[91mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.
Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.
To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.
[0mProcessing /home/vildeeide
Collecting numpy
  Downloading numpy-1.19.0-cp37-cp37m-manylinux2010_x86_64.whl (14.6 MB)
Collecting regex
  Downloading regex-2020.6.8-cp37-cp37m-manylinux2010_x86_64.whl (661 kB)
Collecting tqdm
  Downloading tqdm-4.47.0-py2.py3-none-any.whl (66 kB)
Collecting gym
  Downloading gym-0.17.2.tar.gz (1.6 MB)
Collecting tensorflow>=2.0.0a
  Downloading tensorflow-2.3.0rc0-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)
Collecting scipy
  Downloading scipy-1.5.0-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)
Collecting pyglet<=1.5.0,>=1.4.0
  Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)
Collecting cloudpickle<1.4.0,>=1.2.0
  Downloading cloudpickle-1.3.0-py2.py3-none-any.whl (26 kB)
Collecting absl-py>=0.7.0
  Downloading absl-py-0.9.0.tar.gz (104 kB)
Requirement already satisfied: six>=1.12.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow>=2.0.0a->mitdeeplearning==0.1.2) (1.14.0)
Collecting keras-preprocessing<1.2,>=1.1.1
  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)
Collecting tf-estimator-nightly<2.3.0.dev2020062302,>=2.3.0.dev2020062301
  Downloading tf_estimator_nightly-2.3.0.dev2020062301-py2.py3-none-any.whl (459 kB)
Collecting wrapt>=1.11.1
  Downloading wrapt-1.12.1.tar.gz (27 kB)
Collecting tensorboard<2.3.0,>=2.2.0
  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)
Collecting opt-einsum>=2.3.2
  Downloading opt_einsum-3.2.1-py3-none-any.whl (63 kB)
Collecting protobuf>=3.9.2
  Downloading protobuf-3.12.2-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)
Collecting termcolor>=1.1.0
  Downloading termcolor-1.1.0.tar.gz (3.9 kB)
Collecting astunparse==1.6.3
  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)
Collecting grpcio>=1.8.6
  Downloading grpcio-1.30.0-cp37-cp37m-manylinux2010_x86_64.whl (3.0 MB)
Requirement already satisfied: wheel>=0.26 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow>=2.0.0a->mitdeeplearning==0.1.2) (0.34.1)
Collecting gast==0.3.3
  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)
Collecting h5py<2.11.0,>=2.10.0
  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)
Collecting google-pasta>=0.1.8
  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)
Collecting future
  Downloading future-0.18.2.tar.gz (829 kB)
Collecting werkzeug>=0.11.15
  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)
Requirement already satisfied: setuptools>=41.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0.0a->mitdeeplearning==0.1.2) (45.1.0.post20200119)
Collecting tensorboard-plugin-wit>=1.6.0
  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)
Collecting google-auth-oauthlib<0.5,>=0.4.1
  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)
Collecting markdown>=2.6.8
  Downloading Markdown-3.2.2-py3-none-any.whl (88 kB)
Collecting google-auth<2,>=1.6.3
  Downloading google_auth-1.18.0-py2.py3-none-any.whl (90 kB)
Requirement already satisfied: requests<3,>=2.21.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0.0a->mitdeeplearning==0.1.2) (2.22.0)
Collecting requests-oauthlib>=0.7.0
  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)
Requirement already satisfied: importlib-metadata; python_version < "3.8" in /srv/conda/envs/notebook/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0.0a->mitdeeplearning==0.1.2) (1.5.0)
Collecting pyasn1-modules>=0.2.1
  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)
Collecting rsa<5,>=3.1.4; python_version >= "3"
  Downloading rsa-4.6-py3-none-any.whl (47 kB)
Collecting cachetools<5.0,>=2.0.0
  Downloading cachetools-4.1.1-py3-none-any.whl (10 kB)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0.0a->mitdeeplearning==0.1.2) (1.25.7)
Requirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0.0a->mitdeeplearning==0.1.2) (2019.11.28)
Requirement already satisfied: idna<2.9,>=2.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0.0a->mitdeeplearning==0.1.2) (2.8)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0.0a->mitdeeplearning==0.1.2) (3.0.4)
Requirement already satisfied: oauthlib>=3.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0.0a->mitdeeplearning==0.1.2) (3.0.1)
Requirement already satisfied: zipp>=0.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from importlib-metadata; python_version < "3.8"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0.0a->mitdeeplearning==0.1.2) (2.1.0)
Collecting pyasn1<0.5.0,>=0.4.6
  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)
Building wheels for collected packages: mitdeeplearning, gym, absl-py, wrapt, termcolor, future
  Building wheel for mitdeeplearning (setup.py): started
  Building wheel for mitdeeplearning (setup.py): finished with status 'done'
  Created wheel for mitdeeplearning: filename=mitdeeplearning-0.1.2-py3-none-any.whl size=2115482 sha256=866257c87542f1f41612ead48f4fd66d2f50c9717318ff5aafab959c3e9dfba8
  Stored in directory: /tmp/pip-ephem-wheel-cache-ld7dvk04/wheels/18/1d/f5/bf0f14bf28d31fca5fa5248c6a13f625973319ea6d020a8d96
  Building wheel for gym (setup.py): started
  Building wheel for gym (setup.py): finished with status 'done'
  Created wheel for gym: filename=gym-0.17.2-py3-none-any.whl size=1650892 sha256=a676f93063c293a98dd4504fbf450ca58b8c838f31a5bafcf26c9680167fac2e
  Stored in directory: /tmp/pip-ephem-wheel-cache-ld7dvk04/wheels/18/e1/58/89a2aa24e6c2cc800204fc02010612afdf200926c4d6bfe315
  Building wheel for absl-py (setup.py): started
  Building wheel for absl-py (setup.py): finished with status 'done'
  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=121932 sha256=5220d3fa9ead498ecda36475d01651932b4ce198f3532b024b62fce98c251081
  Stored in directory: /tmp/pip-ephem-wheel-cache-ld7dvk04/wheels/cc/af/1a/498a24d0730ef484019e007bb9e8cef3ac00311a672c049a3e
  Building wheel for wrapt (setup.py): started
  Building wheel for wrapt (setup.py): finished with status 'done'
  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=70965 sha256=35af7d8e2229b9957e106711b3e67f4fd5965a1243c06fc606800125802b7e49
  Stored in directory: /tmp/pip-ephem-wheel-cache-ld7dvk04/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6
  Building wheel for termcolor (setup.py): started
  Building wheel for termcolor (setup.py): finished with status 'done'
  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=6a3fcec8cb2439da78f575c50b2116082b4cad49d55b72448f059e3979321d49
  Stored in directory: /tmp/pip-ephem-wheel-cache-ld7dvk04/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2
  Building wheel for future (setup.py): started
  Building wheel for future (setup.py): finished with status 'done'
  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491056 sha256=cbd1141a72cb7719696b7f095e5cabff17bf6b33c2e723d7abbbea5c8adef1e0
  Stored in directory: /tmp/pip-ephem-wheel-cache-ld7dvk04/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0
Successfully built mitdeeplearning gym absl-py wrapt termcolor future
[91mERROR: tensorflow 2.3.0rc0 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.0 which is incompatible.
ERROR: tensorflow 2.3.0rc0 has requirement scipy==1.4.1, but you'll have scipy 1.5.0 which is incompatible.
[0mInstalling collected packages: numpy, regex, tqdm, scipy, future, pyglet, cloudpickle, gym, absl-py, keras-preprocessing, tf-estimator-nightly, wrapt, werkzeug, tensorboard-plugin-wit, requests-oauthlib, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, google-auth-oauthlib, protobuf, markdown, grpcio, tensorboard, opt-einsum, termcolor, astunparse, gast, h5py, google-pasta, tensorflow, mitdeeplearning
Successfully installed absl-py-0.9.0 astunparse-1.6.3 cachetools-4.1.1 cloudpickle-1.3.0 future-0.18.2 gast-0.3.3 google-auth-1.18.0 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.30.0 gym-0.17.2 h5py-2.10.0 keras-preprocessing-1.1.2 markdown-3.2.2 mitdeeplearning-0.1.2 numpy-1.19.0 opt-einsum-3.2.1 protobuf-3.12.2 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyglet-1.5.0 regex-2020.6.8 requests-oauthlib-1.3.0 rsa-4.6 scipy-1.5.0 tensorboard-2.2.2 tensorboard-plugin-wit-1.7.0 tensorflow-2.3.0rc0 termcolor-1.1.0 tf-estimator-nightly-2.3.0.dev2020062301 tqdm-4.47.0 werkzeug-1.0.1 wrapt-1.12.1
Removing intermediate container 3aad38e3479f
 ---> bcceff919e22
Step 42/48 : LABEL repo2docker.ref="None"
 ---> Running in 691a9bdbd2a5
Removing intermediate container 691a9bdbd2a5
 ---> 81645ea331aa
Step 43/48 : LABEL repo2docker.repo="local"
 ---> Running in 8dfa2cc23648
Removing intermediate container 8dfa2cc23648
 ---> bbf6ff13b25e
Step 44/48 : LABEL repo2docker.version="0.11.0"
 ---> Running in f3ed16b938a2
Removing intermediate container f3ed16b938a2
 ---> e2a7c906690d
Step 45/48 : USER ${NB_USER}
 ---> Running in 80f98afc2960
Removing intermediate container 80f98afc2960
 ---> 72353b604230
Step 46/48 : COPY /repo2docker-entrypoint /usr/local/bin/repo2docker-entrypoint
 ---> 1db55686999b
Step 47/48 : ENTRYPOINT ["/usr/local/bin/repo2docker-entrypoint"]
 ---> Running in f589684c7169
Removing intermediate container f589684c7169
 ---> 1e015583e28c
Step 48/48 : CMD ["jupyter", "notebook", "--ip", "0.0.0.0"]
 ---> Running in ff68361774f4
Removing intermediate container ff68361774f4
 ---> f5f227c73992
{"aux": {"ID": "sha256:f5f227c73992e682fdff4d9a710c58d49c28be35cebb6c5c2ede79b885ae096a"}}Successfully built f5f227c73992
Successfully tagged r2d-test-github.com-aamini-introtodeeplearning:2b44264
